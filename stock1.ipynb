{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV files with company and sector info saved in: path/final_csvs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths\n",
    "root_dir = r\"C:\\Users\\isbmy\\.vscode\\STOCK_PROJECT\\data\"\n",
    "output_dir = \"path/final_csvs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary to collect data per ticker\n",
    "symbol_data = defaultdict(list)\n",
    "\n",
    "# Walk through folders and process YAML\n",
    "for foldername, _, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".yaml\"):\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            with open(filepath, \"r\") as file:\n",
    "                try:\n",
    "                    records = yaml.safe_load(file)\n",
    "                    for record in records:\n",
    "                        symbol = record.get(\"Ticker\")\n",
    "                        if symbol:\n",
    "                            symbol_data[symbol].append(record)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filepath}: {e}\")\n",
    "\n",
    "# Load the sector data\n",
    "sector_df = pd.read_csv(r\"C:\\Users\\isbmy\\.vscode\\STOCK_PROJECT\\data\\Sector_data - Sheet1.csv\")\n",
    "\n",
    "# Ensure column names are consistent for merging\n",
    "sector_df.rename(columns={'Symbol': 'Ticker'}, inplace=True)\n",
    "sector_df['Ticker'] = sector_df['Ticker'].str.split(':').str[-1]\n",
    "\n",
    "# Clean Ticker column (remove leading/trailing spaces)\n",
    "sector_df['Ticker'] = sector_df['Ticker'].str.strip()\n",
    "\n",
    "# Replace specific ticker names to match the records\n",
    "sector_df.replace('ADANIGREEN', 'ADANIENT', inplace=True)\n",
    "sector_df.replace('AIRTEL', 'BHARTIARTL', inplace=True)\n",
    "sector_df.replace('TATACONSUMER', 'TATACONSUM', inplace=True)\n",
    "\n",
    "# Add BRITANNIA data to sector_df\n",
    "sector_df = pd.concat([sector_df, pd.DataFrame([{'COMPANY': 'BRITANNIA INDUSTRIES', 'Ticker': 'BRITANNIA', 'sector': 'CONSUMER GOODS'}])], ignore_index=True)\n",
    "# Add company and sector columns to the existing CSVs\n",
    "for symbol, records in symbol_data.items():\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Merge with sector_df to add company and sector information\n",
    "    df = df.merge(sector_df[['Ticker', 'COMPANY', 'sector']], on='Ticker', how='left')\n",
    "\n",
    "    # Split datetime into date and time\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df['time'] = df['date'].dt.time.astype(str)\n",
    "        df['date'] = df['date'].dt.date.astype(str)\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(os.path.join(output_dir, f\"{symbol}.csv\"), index=False)\n",
    "    if df['COMPANY'].isnull().all():\n",
    "        print(f\"{symbol}.csv: The COMPANY column is empty.\")\n",
    "    elif df['COMPANY'].isnull().any():\n",
    "        print(f\"{symbol}.csv: The COMPANY column has some empty values.\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f\"Updated CSV files with company and sector info saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ce7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to TiDB Cloud SQL\n"
     ]
    }
   ],
   "source": [
    "# Connect to TiDB Cloud SQL\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to TiDB Cloud SQL\n",
    "connection = mysql.connector.connect(\n",
    "    user='3gjpMYnFyBFAYAb.root',\n",
    "    password='J9foCvujVRIFORzR',\n",
    "    host='gateway01.ap-southeast-1.prod.aws.tidbcloud.com',\n",
    "    port='4000'\n",
    ")\n",
    "\n",
    "if connection.is_connected():\n",
    "    print(\"Connected to TiDB Cloud SQL\")\n",
    "else:\n",
    "    print(\"Connection failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4062a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from CSV files saved to TiDB Cloud SQL in database 'stock_data'.\n"
     ]
    }
   ],
   "source": [
    "# Create a database and table for the ticker data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the database and table name\n",
    "database_name = \"stock_data\"\n",
    "table_name = \"ticker\"\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the database if it doesn't exist\n",
    "cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\n",
    "cursor.execute(f\"USE {database_name}\")\n",
    "\n",
    "# Iterate through all CSV files in the output directory\n",
    "for csv_file in os.listdir(output_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(output_dir, csv_file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Create a table for the ticker if it doesn't exist\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join([f'{col} TEXT' for col in df.columns])}\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Insert data into the table\n",
    "        for _, row in df.iterrows():\n",
    "            insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['%s'] * len(row))})\"\n",
    "            cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit the transaction and close the cursor\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "print(f\"Data from CSV files saved to TiDB Cloud SQL in database '{database_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabb4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved at: C:\\Users\\isbmy\\.vscode\\STOCK_PROJECT\\final_csvs\\combined_for_powerbi.csv\n"
     ]
    }
   ],
   "source": [
    "#combine all CSVs into one\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Folder where your individual stock CSVs are stored\n",
    "folder_path = r\"C:\\Users\\isbmy\\.vscode\\STOCK_PROJECT\\final_csvs\"\n",
    "\n",
    "# Get all CSV files in the folder\n",
    "csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine them\n",
    "combined_df = pd.concat(\n",
    "    [pd.read_csv(file).assign(Ticker=os.path.basename(file).replace(\".csv\", \"\")) for file in csv_files],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Save the combined DataFrame to a single CSV\n",
    "output_path = os.path.join(folder_path, \"combined_for_powerbi.csv\")\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to exported_for_powerbi.csv\n"
     ]
    }
   ],
   "source": [
    "#Data Export for Power BI\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Define input/output\n",
    "data_folder = r\"C:\\Users\\isbmy\\.vscode\\STOCK_PROJECT\\final_csvs\"  # Replace with your actual path\n",
    "output_file = \"exported_for_powerbi.csv\"\n",
    "\n",
    "# Load and combine all CSVs\n",
    "df_list = []\n",
    "for file in glob(os.path.join(data_folder, \"*.csv\")):\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        temp_df[\"Ticker\"] = os.path.basename(file).replace(\".csv\", \"\")\n",
    "        df_list.append(temp_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Parse date and sort\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "df = df.sort_values(by=[\"Ticker\", \"date\"])\n",
    "\n",
    "# Add daily return\n",
    "df[\"prev_close\"] = df.groupby(\"Ticker\")[\"close\"].shift(1)\n",
    "df[\"daily_return\"] = (df[\"close\"] - df[\"prev_close\"]) / df[\"prev_close\"]\n",
    "\n",
    "# Add cumulative return\n",
    "cumulative_returns = []\n",
    "for ticker, group in df.groupby(\"Ticker\"):\n",
    "    group = group.copy()\n",
    "    group[\"cumulative_return\"] = (1 + group[\"daily_return\"].fillna(0)).cumprod()\n",
    "    cumulative_returns.append(group)\n",
    "df = pd.concat(cumulative_returns)\n",
    "\n",
    "# Calculate yearly return per ticker\n",
    "yearly_return_df = df.groupby(\"Ticker\").agg(\n",
    "    first_price=(\"close\", \"first\"),\n",
    "    last_price=(\"close\", \"last\")\n",
    ").reset_index()\n",
    "yearly_return_df[\"yearly_return\"] = (yearly_return_df[\"last_price\"] - yearly_return_df[\"first_price\"]) / yearly_return_df[\"first_price\"]\n",
    "\n",
    "# Merge yearly return back to main dataframe\n",
    "df = df.merge(yearly_return_df[[\"Ticker\", \"yearly_return\"]], on=\"Ticker\", how=\"left\")\n",
    "\n",
    "# Add month column\n",
    "df[\"month\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=[\"prev_close\"], inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Data exported to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
